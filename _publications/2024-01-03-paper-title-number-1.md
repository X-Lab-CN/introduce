---
title: "22.Discrete diffusion models with Refined Language-Image Pre-trained representations for remote sensing image captioning"
collection: publications
category: 2024
permalink: /publication/2024-01-03-paper-title-number-1
excerpt: '<div style="text-align: justify;">The paper proposes DDM - RLIP, which applies a discrete diffusion model with refined pre - trained representations to remote sensing image captioning. Experiments on three datasets show it outperforms traditional autoregressive models.</div>'
date: 2024-01-03
venue: 'Pattern Recognition Letters'
paperurl: 'http://xiongyujie.cn/files/Discrete diffusion models with Refined Language-Image Pre-trained representations for remote sensing image captioning.pdf'
citation: '<br/><div style="text-align: justify;">Discrete diffusion models with Refined Language-Image Pre-trained representations for remote sensing image captioning, Guannan Leng, Yu-Jie Xiong*, Chunping Qiu*, Congzhou Guo,Pattern Recognition Letters,2024,186,164-169.</div>'
---

<div style="text-align: justify;">RS image captioning (RSIC) utilizes natural language to provide a description of image content, assisting in the comprehension of object properties and relationships. Nonetheless, RS images are characterized by variations in object scales, distributions, and quantities, which make it challenging to obtain global semantic information and object connections. To enhance the accuracy of captions produced from RS images, this paper proposes a novel method referred to as Discrete Diffusion Models with Refined Language-Image Pretrained representations (DDM-RLIP), leveraging an advanced discrete diffusion model (DDM) for nosing and denoising text tokens. DDM-RLIP is based on an advanced DDM-based method designed for natural pictures. The primary approach for refining image representations involves fine-tuning a CLIP image encoder on RS images, followed by adapting the transformer with an additional attention module to focus on crucial image regions and relevant words. Furthermore, experiments were conducted on three datasets, Sydney-Captions, UCM-Captions, and NWPU-Captions, and the results demonstrated the superior performance of the proposed method compared to conventional autoregressive models. On the NWPU-Captions dataset, the CIDEr score improved from 116.4 to 197.7, further validating the efficacy and potential of DDM-RLIP. The implementation codes for our approach DDM-RLIP are available at https://github.com/Leng-bingo/DDM-RLIP.</div>

<br/>

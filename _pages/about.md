---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

**[School of Electronic and Electrical Engineering](https://seee.sues.edu.cn/)**

**[Shanghai University of Engineering Science](https://www.sues.edu.cn/)**



**Address**:Room 7832/7911, Modern Transportation Engineering Center, No. 333 Longteng Road, Songjiang District, Shanghai

**Contact number**: +86-021-37660073

**Email**: xiong@sues.edu.cn

## üë®‚ÄçüéìIntroduction

<div style="text-align: justify;">üìöXiong Yujie, an associate professor at <a href='https://www.sues.edu.cn/'>[Shanghai University of Engineering Science]</a>, was selected for the 2019 Shanghai Young Science and Technology Talent Sailing Program. He obtained his bachelor's degree in Automation from <a href='https://www.csu.edu.cn/'>[Central South University]</a> in 2011 and his Ph.D. in Computer Application Technology from <a href='https://www.ecnu.edu.cn/'>[East China Normal University]</a> in 2018. In October of the same year, he joined the <a href='https://seee.sues.edu.cn/'>[School of Electronic and Electrical Engineering]</a> at Shanghai University of Engineering Science as a lecturer and was promoted to associate professor in December 2021. His representative research work includes multi-language offline signature verification in complex scenarios, continuous large-scale action detection for video streams, multi-modal data fusion analysis for traditional Chinese medicine diagnostics, chain-of-thought reasoning technology for large language models, and high-fidelity 3D modeling for real-time dynamic small scenes. </div>

<div style="text-align: justify;">üìñHe has presided over more than 10 scientific research projects, including the National Natural Science Foundation of China Youth Project, Shanghai Municipal Science and Technology Commission projects, Shanghai Municipal Education Commission projects, and enterprise-entrusted projects. He has also participated in major projects such as the Innovation 2030‚Äî"New Generation Artificial Intelligence" project, National Natural Science Foundation projects, and Shanghai Municipal Science and Technology Commission projects. He has published over 50 academic papers and serves as a member of the program committees for several international conferences. As an expert with the ISO International Organization for Standardization, he has participated in the review of multiple TC249 traditional Chinese medicine standard projects and contributed to the drafting of national standards "Traditional Chinese Medicine‚ÄîDiagnostic Vocabulary‚ÄîPart 1: Tongue Manifestations" and "Traditional Chinese Medicine‚ÄîDiagnostic Vocabulary‚ÄîPart 2: Pulse Manifestations."</div>

## üìùSelected Publications
Please see [Publications](https://xiongyujie.cn/publications/) for more details.

*ÔºöCorresponding author

------

<table style="width: 100%; border: none; border-collapse: collapse;">
  <tr>
    <td style="width: 35%; border: none; padding: 0; vertical-align: middle; position: relative;">
      <div style="position: absolute; top: 10px; left: -8px;
           background: #1a73e8; color: white;
           padding: 2px 15px; /* È´òÂ∫¶ÂáèÂ∞ëÔºàÂéü‰∏∫3pxÔºâ */
           font-size: 11px;  /* Â≠ó‰ΩìÁ®çÂ∞è */
           border-bottom-right-radius: 4px; 
           box-shadow: 1px 1px 3px rgba(0,0,0,0.2);
           font-weight: normal;
           line-height: 1.2;"> <!-- Ë∞ÉÊï¥Ë°åÈ´ò -->
        COLING 2025
      </div>
      <img src="/images/sp1.png" alt="ÂõæÁâáÊèèËø∞" 
           style="width: 500px; height: 150px; 
           box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.3); 
           border-radius: 4px;">
    </td>
    <td style="width: 65%; border: none; padding-left: 40px; vertical-align: middle;">
      <a href="https://xiongyujie.cn/publication/2025-01-19-paper-title-number-1">
        Parameter-Efficient Fine-Tuning of Large Language Models via Deconvolution in Subspace
      </a><br/>
      Jia-Chen Zhang, Yu-Jie Xiong*, Chun-Ming Xia, Dong-Hai Zhu, Xi-He Qiu<br/>
      In <i>Proceedings of the 31st International Conference on Computational Linguistics</i>,2025<br/>
      <a href="https://github.com/Godz-z/DCFT" style="color: #1a73e8; text-decoration: none;">Code</a> | 
      <a href="https://xiongyujie.cn/files/Parameter-Efficient_Fine-Tuning_of_Large_Language_Models_via_Deconvolution_in_Subspace.pdf" style="color: #1a73e8; text-decoration: none;">PDF</a>
    </td>
  </tr>
</table>
<table style="width: 100%; border: none; border-collapse: collapse;">
  <tr>
    <td style="width: 35%; border: none; padding: 0; vertical-align: middle; position: relative;">
      <div style="position: absolute; top: 10px; left: -8px;
           background: #1a73e8; color: white;
           padding: 2px 15px; /* È´òÂ∫¶ÂáèÂ∞ëÔºàÂéü‰∏∫3pxÔºâ */
           font-size: 11px;  /* Â≠ó‰ΩìÁ®çÂ∞è */
           border-bottom-right-radius: 4px; 
           box-shadow: 1px 1px 3px rgba(0,0,0,0.2);
           font-weight: normal;
           line-height: 1.2;"> <!-- Ë∞ÉÊï¥Ë°åÈ´ò -->
         Pattern Recognition 2024
      </div>
      <img src="/images/sp2.png" alt="ÂõæÁâáÊèèËø∞" 
           style="width: 500px; height: 150px; 
           box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.3); 
           border-radius: 4px;">
    </td>
    <td style="width: 65%; border: none; padding-left: 40px; vertical-align: middle;">
      <a href="https://xiongyujie.cn/publication/2023-11-22-paper-title-number-1">
        Multi-view hypergraph regularized Lp norm least squares twin support vector machines for semi-supervised learning
      </a><br/>
       Junqi Lu, Xijiong Xie*, Yujie Xiong<br/>
      In <i>Pattern Recognition</i>,2024<br/>
      <a href="https://xiongyujie.cn/files/Multi-view_hypergraph_regularized_Lp_norm_least_squares_twin_support_vector_machines_for_semi-supervised_learning.pdf" style="color: #1a73e8; text-decoration: none;">PDF</a>
    </td>
  </tr>
</table>
<table style="width: 100%; border: none; border-collapse: collapse;">
  <tr>
    <td style="width: 35%; border: none; padding: 0; vertical-align: middle; position: relative;">
      <div style="position: absolute; top: 10px; left: -8px;
           background: #1a73e8; color: white;
           padding: 2px 15px; /* È´òÂ∫¶ÂáèÂ∞ëÔºàÂéü‰∏∫3pxÔºâ */
           font-size: 11px;  /* Â≠ó‰ΩìÁ®çÂ∞è */
           border-bottom-right-radius: 4px; 
           box-shadow: 1px 1px 3px rgba(0,0,0,0.2);
           font-weight: normal;
           line-height: 1.2;"> <!-- Ë∞ÉÊï¥Ë°åÈ´ò -->
         Biomedical Signal Processing and Control 2024
      </div>
      <img src="/images/sp3.png" alt="ÂõæÁâáÊèèËø∞" 
           style="width: 500px; height: 150px; 
           box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.3); 
           border-radius: 4px;">
    </td>
    <td style="width: 65%; border: none; padding-left: 40px; vertical-align: middle;">
      <a href="https://xiongyujie.cn/publication/2024-10-10-paper-title-number-4">
        Harmonious parameters and performance: Lightweight convolutional stage and local feature weighted fusion MLP for medical image segmentation
      </a><br/>
        Yan-Xu Chen, Yu-Jie Xiong*, Xi-He Qiu, Chun-Ming Xia*<br/>
      In <i>Biomedical Signal Processing and Control</i>,2024<br/>
      <a href="https://xiongyujie.cn/files/Harmonious_parameters_and_performance_Lightweight_convolutional_stage_and_local_feature_weighted_fusion_MLP_for_medical_image_segmentation.pdf" style="color: #1a73e8; text-decoration: none;">PDF</a>
    </td>
  </tr>
</table>
<table style="width: 100%; border: none; border-collapse: collapse;">
  <tr>
    <td style="width: 35%; border: none; padding: 0; vertical-align: middle; position: relative;">
      <div style="position: absolute; top: 10px; left: -8px;
           background: #1a73e8; color: white;
           padding: 2px 15px; /* È´òÂ∫¶ÂáèÂ∞ëÔºàÂéü‰∏∫3pxÔºâ */
           font-size: 11px;  /* Â≠ó‰ΩìÁ®çÂ∞è */
           border-bottom-right-radius: 4px; 
           box-shadow: 1px 1px 3px rgba(0,0,0,0.2);
           font-weight: normal;
           line-height: 1.2;"> <!-- Ë∞ÉÊï¥Ë°åÈ´ò -->
         Engineering Applications of Artificial Intelligence 2023
      </div>
      <img src="/images/sp4.png" alt="ÂõæÁâáÊèèËø∞" 
           style="width: 500px; height: 150px; 
           box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.3); 
           border-radius: 4px;">
    </td>
    <td style="width: 65%; border: none; padding-left: 40px; vertical-align: middle;">
      <a href="https://xiongyujie.cn/publication/2023-10-20-paper-title-number-1">
        Adaptive graph-based feature normalization for facial expression recognition
      </a><br/>
         Yu-Jie Xionga*, Qingqing Wang*, Yangtao Du, Yue Lu<br/>
      In <i>Engineering Applications of Artificial Intelligence</i>,2023<br/>
      <a href="https://xiongyujie.cn/files/Adaptive_graph-based_feature_normalization_for_facial_expression_recognition.pdf" style="color: #1a73e8; text-decoration: none;">PDF</a>
    </td>
  </tr>
</table>
<table style="width: 100%; border: none; border-collapse: collapse;">
  <tr>
    <td style="width: 35%; border: none; padding: 0; vertical-align: middle; position: relative;">
      <div style="position: absolute; top: 10px; left: -8px;
           background: #1a73e8; color: white;
           padding: 2px 15px; /* È´òÂ∫¶ÂáèÂ∞ëÔºàÂéü‰∏∫3pxÔºâ */
           font-size: 11px;  /* Â≠ó‰ΩìÁ®çÂ∞è */
           border-bottom-right-radius: 4px; 
           box-shadow: 1px 1px 3px rgba(0,0,0,0.2);
           font-weight: normal;
           line-height: 1.2;"> <!-- Ë∞ÉÊï¥Ë°åÈ´ò -->
         Engineering Applications of Artificial Intelligence 2022
      </div>
      <img src="/images/sp5.png" alt="ÂõæÁâáÊèèËø∞" 
           style="width: 500px; height: 150px; 
           box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.3); 
           border-radius: 4px;">
    </td>
    <td style="width: 65%; border: none; padding-left: 40px; vertical-align: middle;">
      <a href="https://xiongyujie.cn/publication/2022-07-29-paper-title-number-1">
        2C2S: A two-channel and two-stream transformer based framework for offline signature verification
      </a><br/>
         Jian-Xin Ren, Yu-Jie Xiong*, Hongjian Zhan, Bo Huang<br/>
      In <i>Engineering Applications of Artificial Intelligence</i>,2022<br/>
      <a href="https://xiongyujie.cn/files/2C2S_A_two-channel_and_two-stream_transformer_based_framework_for_offline_signature_verification.pdf" style="color: #1a73e8; text-decoration: none;">PDF</a>
    </td>
  </tr>
</table>

### Publications List

We provide a complete list of research papers.
 

<details>
  <summary>
    <b>Publications List</b>
  </summary>
        <ol>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S1746809424007845">
                    <p>Harmonious parameters and performance: Lightweight convolutional stage and local feature weighted
                        fusion MLP for medical image segmentation</a>,
                Y.-X. Chen, <strong>Y.-J. Xiong*</strong>, X.-H. Qiu and C.-M. Xia*,
                <em>Biomedical Signal Processing and Control</em>, 2024, 98: 106726</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhEQ-0D2ex_F0Y-gyTIz3KqenBWzpErLRF7fkIODwXBa_NEopSWqlLA6uXhKAZK1lenpaNdg3CAY48Qbt--DZLHxXAZ-SmR78DqMVHLnwO4rdvpIFE55Oi1uohhm7hiBFEy_qyvq0Tj0c1Ezi36ZvUhwdQpttraOloL79uHVx_8DyuSNHgNKJbDX1p01G7R3vtdx53VBxf8EiIhhHkPlyTGe&uniplatform=NZKPT&language=CHS">
                    <p>Âü∫‰∫éTransformer‰∏éVector LossÊ®°ÂùóÁöÑÊ§éÈ™®CobbËßíÁÇπÂÆö‰ΩçÁΩëÁªú</a>,
                ÈôàÁë∂ÔºåÈ´òÊ∞∏ÂΩ¨*Ôºå<strong>ÁÜäÁéâÊ¥Å</strong>,
                „Ää‰∏≠ÂõΩÂåªÂ≠¶Áâ©ÁêÜÂ≠¶ÊùÇÂøó„ÄãÔºå2022Ôºå39 (11): 1393-1400</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhFkEKghoC5GHNtZILtQJtxWCZPqOb5Vi8Z09s3sY-lZuoyfuLduSvw-dpnvcLih947QfeXGyUK8HmdLA-EjYjZTeXNXlL19j5uS4SEG7s4pGCOZRO71WCsJIFThKuuD0TOlhtoUR9cZzquWSzBWeS6sH9z-A-9Mo0QykFYyJF0e1OHHP6nERZVRbCGibZqlWaIpd8JekWfuSEMtqO6-XYY0PCB99HWGoJx7zQYsqwS0EOCLCxSyXCN64B-2u8TYM7xBJhwxt1RvHA==&uniplatform=NZKPT&language=CHS">
                    <p>‰∏§Èò∂ÊÆµÈóÆÁ≠îËåÉÂºèÁöÑÁîüÁâ©ÂåªÂ≠¶‰∫ã‰ª∂Ëß¶ÂèëËØçÊ£ÄÊµã</a>,
                Ë°åÂ∏ÖÔºå<strong>ÁÜäÁéâÊ¥Å*</strong>ÔºåËãèÂâçÊïè*ÔºåÈªÑÁªßÊ±â,
                ËÆ°ÁÆóÊú∫Â∑•Á®ã‰∏éÂ∫îÁî®, ÁΩëÁªúÈ¶ñÂèë (2023)</p>
            </li>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0141938223002615">
                    <p>CODP-1200: An AIGC based benchmark for assisting in child language acquisition</a>,
                G. Leng, G. Zhang, <strong>Y.-J. Xiong*</strong> and J. Chen,
                <em>Displays</em>, 2023, 82: 102627</p>
            </li>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0952197623018079">
                    <p>Adaptive graph-based feature normalization for facial expression recognition</a>,
                <strong>Y.-J. Xiong*</strong>, Q. Wang, Y.-T. Du and Y. Lu,
                <em>Engineering Applications of Artificial Intelligence</em>, 2024, 129: 107623</p>
            </li>
            <li>
                <a href="https://arxiv.org/abs/2501.04341">
                    <p>Understanding Before Reasoning: Enhancing Chain-of-Thought with Iterative Summarization Pre-Prompting</a>,
                D.-H. Zhu, <strong>Y.-J. Xiong*</strong>, J.-C. Zhang, X.-J. Xie, C.-M. Xia,
                <em>arxiv preprint</em>, arxiv:2501.04341¬†(2025)</p>
            </li>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0952197624019729">
                    <p>Triplet trustworthiness validation with knowledge graph reasoning</a>,
                G. Zhang, <strong>Y.-J. Xiong*</strong>, J.-P. Hu, C.-M. Xia,
                <em>Engineering Applications of Artificial Intelligence</em>, 2025,146: 109813</p>
            </li>
            <li>
                <a href="https://aclanthology.org/2025.coling-main.265/">
                    <p>Parameter-Efficient Fine-Tuning of Large Language Models via Deconvolution in Subspace</a>,
                J.-C. Zhang, <strong>Y.-J. Xiong*</strong>, C.-M. Xia, D.-H. Zhu, X.-H. Qiu,
                <em>Proceedings of the 31st International Conference on Computational Linguistics</em>, 2025: 3924-3935</p>
            </li>
            <li>
                <a href="https://dl.acm.org/doi/abs/10.1145/3664647.3681045">
                    <p>Free Lunch: Frame-level Contrastive Learning with Text Perceiver for Robust Scene Text Recognition in Lightweight Models</a>,
                H.-J. Zhan, Y.-F. Li*, <strong>Y.-J. Xiong</strong>, Umapada Pal, Y. Lu,
                <em>Proceedings of the 32nd ACM International Conference on Multimedia</em>, 2024</p>
            </li>
            <li>
                <a href="https://wujns.edpsciences.org/articles/wujns/abs/2024/02/wujns-1007-1202-2024-02-0125-09/wujns-1007-1202-2024-02-0125-09.html">
                    <p>Few-Shot Named Entity Recognition with the Integration of Spatial Features</a>,
                Z.-W. Liu, B. Huang*, C.-M. Xia, <strong>Y.-J. Xiong</strong>, Z.-S. Zhang, Y.-Q. Zhang,
                <em>Wuhan University Journal of Natural Sciences</em>, 2024,29.2: 125-133</p>
            </li>
            <li>
                <a href="https://ieeexplore.ieee.org/abstract/document/10777444">
                    <p>PointABM: Integrating Bidirectional Mamba and Multi-Head Self-Attention for Point Cloud Analysis</a>,
                J.-W. Chen, <strong>Y.-J. Xiong*</strong>, D.-H. Zhu, J.-C. Zhang, Z. Zhou,
                <em>2024 4th International Conference on Intelligent Technology and Embedded Systems (ICITES). IEEE</em>, 2024</p>
            </li>
            <li>
                <a href="https://arxiv.org/abs/2408.06854">
                    <p>LoRA¬≤ :Multi-Scale Low-Rank Approximations for Fine-Tuning Large Language Models</a>,
                J.-C. Zhang, <strong>Y.-J. Xiong*</strong>, X.-H. Qiu, D.-H. Zhu, C.-M. Xia,
                <em>arxiv preprint</em>, arxiv:2408.06854¬†(2024)</p>
            </li>
            <li>
                <a href="https://arxiv.org/abs/2407.12532">
                    <p>Towards Collaborative Intelligence: Propagating Intentions and Reasoning for Multi-Agent Coordination with Large Language Models</a>,
                X.-H. Qiu*, H.-Y. Wang, X.-Y. Tan, C. Qu, <strong>Y.-J. Xiong</strong>, Y. Chen, Y.-H. Xu, W. Chu, Y. Qi,
                <em>arxiv preprint</em>, arxiv:2407.12532¬†(2024)</p>
            </li>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S1566253524006146">
                    <p>AutoGRN: An adaptive multi-channel graph recurrent joint optimization network with Copula-based dependency modeling for spatio-temporal fusion in electrical power systems</a>,
                H.-Y. Wang, X.-H. Qiu*, <strong>Y.-J. Xiong</strong>, X.-Y. Tan,
                <em>Information Fusion</em>, 2024: 102836</p>
            </li>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0167404824003638?via=ihub">
                    <p>Transformer-based end-to-end attack on text CAPTCHAs with triplet deep attention</a>,
                B. Zhang, <strong>Y.-J. Xiong*</strong>, C.-M. Xia and Y.-B. Gao,
                <em>Computers & Security</em>, 2024, 146: 104058</p>
            </li>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0957417423036035">
                    <p>Enhanced video clustering using multiple riemannian manifold-valued descriptors and audio-visual
                        information</a>,
                W. Hu, H. Zhan*, Y. Tian, <strong>Y.-J. Xiong</strong> and Y. Lu,
                <em>Expert Systems with Applications</em>, 2024, 246: 123099</p>
            </li>
            <li>
                <a href="https://www.mdpi.com/2076-3417/14/11/4906">
                    <p>Text Classification Model Based on Graph Attention Networks and Adversarial Training</a>,
                J. Li, Y. Jian* and <strong>Y.-J. Xiong</strong>,
                <em>Applied Sciences</em>, 2024, 14(11): 4906</p>
            </li>

            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0031320324005041">
                    <p>Multi-view hypergraph regularized Lp norm least squares twin support vector machines for
                        semi-supervised learning</a>,
                J. Lu, X.-J. Xie* and <strong>Y.-J. Xiong</strong>,
                <em>Pattern Recognition</em>, 2024, 156: 110753</p>
            </li>
            <li>
                <a href="https://ieeexplore.ieee.org/abstract/document/10674771">
                    <p>Kalman-SSM: Modeling Long-Term Time Series With Kalman Filter Structured State Spaces</a>,
                Z. Zhou, X. Guo, <strong>Y.-J. Xiong*</strong> and C.-M. Xia,
                <em>IEEE Signal Processing Letters</em>, 2024, 31: 2470-2474</p>
            </li>
            <li>
                <a href="https://link.springer.com/chapter/10.1007/978-3-031-53308-2_37">
                    <p>LRATNet: Local-Relationship-Aware Transformer Network for Table Structure Recognition</a>,
                G. Yang, D. Zhong, <strong>Y.-J. Xiong</strong> and H. Zhan*,
                in Proceedings of the <em>International Conference on MultiMedia Modeling (MMM)</em>, Lecture
                Notes in Computer Science, vol 14555, (2024)pp. 441-452</p>
            </li>

            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0957417423006978"><p>PDCSN: A partition
                    density clustering with self-adaptive neighborhoods</a>,
                S. Xing, Q.-M. Su*, <strong>Y.-J. Xiong*</strong>, C.-M. Xia,Expert Systems With Applications, 2023, 227
                (1): 120195</p>
            </li>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0952197622006297"><p>2C2S: A two-channel and
                    two-stream transformer based framework for offline signature verification</a>,
                J.-X. Ren, <strong>Y.-J. Xiong*</strong>, H. Zhan and B. Huang,
                Engineering Applications of Artificial Intelligence, 2023, 118 (1): 105639</p>
            </li>
            <li>
                <a href="https://link.springer.com/article/10.1007/s11063-022-11004-3"><p>Learning Transferable Feature
                    Representation with Swin Transformer for Object Recognition</a>,
                J.-X. Ren, <strong>Y.-J. Xiong*</strong>, X.-J. Xie and Y.-F. Dai,
                Neural Processing Letters, 2023, 55 (1): 2211‚Äì2223</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhE2RgKa2J03PDCsX4XxR7hbUgUVVBOGxM2QhbZwaDgbRjKrXflfythDYAZFfAzEO98wJJM2Xnv0U53jF-4Y5DJ9xQgcZ148boo3jLX8NAVys0UJkbjSKn28vd7PoIhZiLDgqhoN9iCbdXsK4D3YBsp48JjNZRCnhNn0tIg1lhleWFQK3IJSjmj_7EUfHbfSxgC7wlJfRFfbbA_r97Azf0KeMwHELb6icuSPhkzwBNmPuA==&uniplatform=NZKPT&language=CHS">
                    <p>ÁªìÂêàÂèåÈáëÂ≠óÂ°îÁâπÂæÅËûçÂêà‰∏éÁ∫ßËÅîÂÆö‰ΩçÁöÑËΩ¶ÁâåÊ£ÄÊµã</a>,
                Âº†‰øäÈùíÔºå<strong>ÁÜäÁéâÊ¥Å*</strong>ÔºåÂ≠ôÂÆ™Âù§ÔºåÈ´òÊ∞∏ÂΩ¨,
                „ÄäËÆ°ÁÆóÊú∫Â∑•Á®ã‰∏éÂ∫îÁî®„ÄãÔºå2023Ôºå59 (2): 240-252</p>
            </li>
            <li>
                <a href="https://link.springer.com/article/10.1007/s10032-023-00455-6"><p>Attention-based multiple
                    siamese networks with primary representation guiding for offline signature verification</a>,
                <strong>Y.-J. Xiong*</strong>, S.-Y. Cheng, J.-X. Ren and Y.-J. Zhang,
                International Journal on Document Analysis and Recognition, online (2023)</p>
            </li>
            <li>
                <a href="https://ieeexplore.ieee.org/abstract/document/10476175"><p>Deep Frame-Point Sequence Consistent
                    Network for Handwriting Trajectory Recovery</a>,
                <strong>Y.-J. Xiong</strong>, Y.-F. Dai and D. Meng*,
                in Proceedings of the International Conference on Parallel and Distributed Systems, accepted (2023)</p>
            </li>
            <li>
                <a href="https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/cps2.12080"><p>Multiple dependence
                    representation of attention graph convolutional network relation extraction model</a>,
                L.-F. Zhao, <strong>Y.-J. Xiong*</strong>, Y.-B. Gao and W.-J. Yu,
                IET Cyber-Physical Systems: Theory & Applications, online (2023)</p>
            </li>
            <li>
                <a href="https://ieeexplore.ieee.org/abstract/document/10189467"><p>SET: A squeeze-and-excitation
                    transformer for offline signature verification</a>,
                J.-X. Ren, J. Chen* and <strong>Y.-J. Xiong*</strong>,in Proceedings of the International Conference on
                Ubiquitous Intelligence and Computing, (2022) pp. 1812-1816</p>
            </li>
            <li>
                <a href="https://www.mdpi.com/2079-9292/11/23/3895"><p>License Plate Detection with Attention-Guided
                    Dual Feature Pyramid Networks in Complex Environments</a>,
                <strong>Y.-J. Xiong*</strong>, Y.-B. Gao*, J.-Q. Zhang and J.-X. Ren,
                Electronics, 2022, 11 (23): 3895</p>
            </li>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0957417421017681"><p>Generalized multi-view
                    learning based on generalized eigenvalues proximal support vector machines</a>,
                X.-J. Xie* and <strong>Y.-J. Xiong</strong>,
                Expert Systems with Applications, 2022, 194 (1): 116491</p>
            </li>
            <li>
                <a href="https://www.worldscientific.com/doi/abs/10.1142/S0218126622500128"><p>Mitigating
                    Lifetime-Energy-Makespan Issues in Reliability-Aware Workflow Scheduling for Big Data</a>,
                <strong>Y.-J. Xiong*</strong>, S.-Y. Cheng and B. Chen,
                Journal of Circuits, Systems and Computers, 2022, 31 (1): 2250012</p>
            </li>
            <li>
                <a href="https://www.sciencedirect.com/science/article/pii/S0140366422001426"><p>A cross entropy based
                    approach to minimum propagation latency for controller placement in Software Defined Network</a>,
                J. Chen, <strong>Y.-J. Xiong*</strong>, X.-H. Qiu, D. He, H.-M. Yin and Y.-F. Xiao,
                Computer Communications, 2022, 191 (1): 133-144</p>
            </li>
            <li>
                <a href="https://ieeexplore.ieee.org/abstract/document/9903224"><p>A Density-based Controller Placement
                    Algorithm for Software Defined Networks</a>,
                J. Chen, <strong>Y.-J. Xiong*</strong> and D. He,
                in Proceedings of the International Conference on Cyber, Physical and Social Computing, (2022) pp.
                287-291</p>
            </li>
            <li>
                <a href="https://link.springer.com/article/10.1007/s10489-022-03779-8"><p>Knowledge distilled
                    pre-training model for vision-language-navigation</a>,
                B. Huang*, S. Zhang, J.-T. Huang, Y.-J. Yu, Z.-C. Shi and <strong>Y.-J. Xiong</strong>,
                Applied Intelligence, 2022, 53 (1): 5607‚Äì5619</p>
            </li>
            <li>
                <a href="https://doi.org/10.1142/S0218126622500128"><p>Mitigating Lifetime-Energy-Makespan Issues in
                    Reliability-Aware Workflow Scheduling for Big Data</a>,
                <strong>Y.-J. Xiong*</strong>, S.-Y. Cheng and B. Chen,
                Journal of Circuits, Systems and Computers, 2022, 31 (1): 2250012</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhGMvPNXWcCDuyeWExYwlWLnBK6UtR65hO_mLne95o923ftwezFcnaDAAs96TdAkjkmFyLSF6bMsZGT7QfHJbaNsrltHzoSSI5AAgPuKjP0lYFx2KyRUKFANYI1KLlIYzHFcDWxKgwlLePnD0GOS_lJzkFj0azP0lG4gqNwR16u6zNu2XA2tx58kF13EWqlVSm2XxN0NxQQIgfA9jQ7XDxGfEhiDKEORtwPOL9Th7evtgYBYlFWS68M5YBiDx7c9JIA-arh3oHCHvQ==&uniplatform=NZKPT&language=CHS">
                    <p>ÁªìÂêàÊï∞ÊçÆÊâ©Â¢û‰∏éÊÆãÂ∑ÆÊî∂Áº©ÁΩëÁªúÁöÑÂú∞ÈúáÁü≠‰∏¥È¢ÑÊµã</a>,
                Âº†ÁøîÔºåÂ≠ôÂÆ™Âù§*ÔºåËÉ°Â≥ªÔºåÂ∞π‰∫¨ËãëÔºå<strong>ÁÜäÁéâÊ¥Å</strong>,
                „ÄäÂú∞Èúá„ÄãÔºå2022Ôºå42 (2): 74-88</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhHwXO2WDvDv2Z3CPLa2oRQg6BDIAbXcWyR_WoomgGF1pZ3Wvr0IVL3gVgRzvRyEgw4H2xZOgJB7vP04YjtzzvwTRKEM2cB0oDs1905iE3vUloXBfjdILbVZNhcXMhtP62xjySw6A8mQhOShffmXOBBG2D1Ykvxfs4FHCx5SozS6XdD8Ayjo7B8HbOo8ZITZuZbDblDaibg5jDLNCPG5whd2&uniplatform=NZKPT&language=CHS">
                    <p>Âü∫‰∫é PWC-Net ÁöÑÂ§öÂ±ÇÊùÉÂÄºÂíåËΩªÈáèÂåñÊîπËøõÂÖâÊµÅ‰º∞ËÆ°ÁÆóÊ≥ï</a>,
                ËÉ°ÊØÖËΩ©ÔºåÂê¥È£û*Ôºå<strong>ÁÜäÁéâÊ¥Å</strong>,
                „ÄäËÆ°ÁÆóÊú∫Â∫îÁî®Á†îÁ©∂„ÄãÔºå2022Ôºå39 (1): 291-295</p>
            </li>
            <li>
                <a href="https://www.spiedigitallibrary.org/journals/journal-of-electronic-imaging/volume-30/issue-3/033024/PC-SuperPoint--interest-point-detection-and-descriptor-extraction-using/10.1117/1.JEI.30.3.033024.short#_=_">
                    <p>PC-SuperPoint: interest point detection and descriptor extraction using pyramid convolution and
                        circle loss</a>,
                <strong>Y.-J. Xiong*</strong>, S. Ma, Y.-B. Gao and Z.-J. Fang,
                Journal of Electronic Imaging, 2021, 30 (3): 033024</p>
            </li>
            <li>
                <a href="https://www.worldscientific.com/doi/abs/10.1142/S0218126621502728"><p>Attention U-Net with
                    Feature Fusion Module for Robust Defect Detection</a>,
                <strong>Y.-J. Xiong*</strong>, Y.-B. Gao, H. Wu and Y. Yao,
                Journal of Circuits, Systems and Computers, 2021, 30 (15): 2150272</p>
            </li>
            <li>
                <a href="https://link.springer.com/chapter/10.1007/978-3-030-86334-0_22"><p>Attention Based Multiple
                    Siamese Network for Offline Signature Verification</a>,
                <strong>Y.-J. Xiong*</strong> and S.-Y. Cheng,
                in Proceedings of the International Conference on Document Analysis and Recognition, (2021) pp.
                337-349</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhHQ_2c6X3KY24xws0S01OWcUzO7MDqvHIlwJ_cgMpw9R_Civ_nOVoOnZX1ti2gQiSQ2s2ta74zfzZJtJIUiJWOvxTFqMQntYMNoOLm525udTJjfRWh6sgW3o0rx5EZ_KCeOhbpm_yv4i0d5Z2-wcOHd7e0M0ICtZArveh9O1akTbdgX3V-ilnDCOX_KxS8LQKmWtrLy3eDjiCWnTmA6bJVB&uniplatform=NZKPT&language=CHS">
                    <p>Attention U-Net with Multilevel Fusion for License Plate Detection</a>,
                Y. Yao, <strong>Y.-J. Xiong*</strong>, B. Huang and J. Yang,
                Wuhan University Journal of Natural Sciences, 2021, 26 (3): 227-234</p>
            </li>
            <li>
                <a href="https://link.springer.com/chapter/10.1007/978-981-16-1194-0_17"><p>An Empirical Study of Text
                    Factors and Their Effects on Chinese Writer Identification</a>,
                <strong>Y.-J. Xiong*</strong>, Y. Lu and Y.-C. Cao,
                Digital TV and Wireless Multimedia Communication, (2021) pp. 194-205</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhG-VkyuIP5ANtfkc2CB8mxCjMPXK2giNCCabeFmsyouxbLrQOwzq7Hou3FW6_beoIIrFsS8g1ugx5kDZbnz1KhIpjc5skmqsvJpe4aDuH27UXMtWarkhWqRXiabXAlrPLNE2q80GTavKIVVFyoGqt3Ik9Ecc81spQScMsAzJpfRuRuCwmuhYZL0wROvnz7Ch1DkcvoUSSohrTsIvIh_L-Br&uniplatform=NZKPT&language=CHS">
                    <p>ÁªìÂêàÂÄíÁΩÆÁâπÂæÅÈáëÂ≠óÂ°îÂíåU-NetÁöÑÈ´òÂÖâË∞±ÂõæÂÉèÂàÜÁ±ª</a>,
                Á®ãÂµ©Èò≥Ôºå<strong>ÁÜäÁéâÊ¥Å*</strong>ÔºåÂßöÁë∂ÔºåÊùéÂ∫ÜÂà©,
                „Ää‰∏≠ÂõΩÂõæË±°ÂõæÂΩ¢Â≠¶Êä•„ÄãÔºå2021Ôºå26 (8): 1994-2008</p>
            </li>
            <li>
                <a href="https://link.springer.com/chapter/10.1007/978-3-030-59830-3_31"><p>Handwriting and
                    Hand-Sketched Graphics Detection Using Convolutional Neural Networks</a>,
                S.-Y. Cheng, <strong>Y.-J. Xiong*</strong>, J.-Q. Zhang and Y.-C. Cao,
                in Proceedings of the International Conference on Pattern Recognition and Artificial Intelligence,
                (2020) pp. 352-362</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhGelQLIXCVg8me4zmnRj4rbxPJJQbGBhZBnkqZ_vP6biuM3CD9uJjI2cUTetjagL5MTIhWHLhe_oMc7IdoCmMZgX7yIu0lNR4UdRcU5hymM05WAjdEUW0HGH_4O9SOuEEeGDb7LcUy010iFctIABdam9g-zUlFvDmserAICnXA8fQbyyAp2c0KjNGD0O1jQNJdwboVYBFKFiIaZxdhNdzPJpuT2Rv51NfzwaRmoV6WLqKZ1Zvyhl4bTkAmNbryfnK4=&uniplatform=NZKPT&language=CHS">
                    <p>A Lightweight Improved U-Net with Shallow Features Combination and Its Application to Defect
                        Detection</a>
                H. Wu, X.-K. Sun*, <strong>Y.-J. Xiong</strong>,
                Wuhan University Journal of Natural Sciences, 2020, 25 (5): 461-468</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhFGMOamXa6kX5oDcs8LiWMrw8abArDf7DUzSV0Ny8lXojGjVx3gnS0cpDfRoASBH1KYWIdpJLoiOTSsdgzJj9VlXbHZWUNa3mQUzz3w_0ZnDt4HlhDLHdKnXHeiuVfJ8GJEBRerCCMEnAch258WyNXzgFdyq8ePPly9PwLlGvq0tc6LxOWvskxubT0aaAkOWwg4iRKPS0B6BKwPBtJhl3I_&uniplatform=NZKPT&language=CHS">
                    <p>Âü∫‰∫éÊîπËøõADRCÁöÑÂõõÊóãÁøºÊó†‰∫∫Êú∫ÊäóÂπ≤Êâ∞ÂßøÊÄÅÊéßÂà∂Á≥ªÁªüËÆæËÆ°</a>,
                ‰ΩôÂ∞èÁáïÔºåÂ≠ôÂÆ™Âù§*Ôºå<strong>ÁÜäÁéâÊ¥Å</strong>ÔºåËÉ°Ê∏ÖÁ§ºÔºåÈôàÂñÑÈπè,
                „ÄäÁîµÂÖâ‰∏éÊéßÂà∂„ÄãÔºå2020Ôºå27 (12): 78-83</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhGeW8wPKBM1ZZupqM7FtNEczdY5NQ8fTgwdmYxdVbIVRaYoVfYJTOBmD9AJbTTqlHfdEycuZS1JtsUSH8Pe84Gs7m1itW1lC2ZA1SG63Ahiofzgt-XYoDM--zHU3odBC51aBNHgqt1VY6DOFPjm3HOcPofVJwOTMJZkWL5NUdBV9CmiYsMbtH9YE_3gVDtjlVGrA6gxT3Dlz_OYfzl0oDhhMbSEIwLug0Yk2xKL89f89QHHXqyT_BVN8rbTp9WXMDA3H2Z5oyvvKQ==&uniplatform=NZKPT&language=CHS">
                    <p>ÊîπËøõÈÅó‰º†ÁÆóÊ≥ïÁöÑÊó†‰∫∫Êú∫Ë∑ØÂæÑËßÑÂàí</a>,
                ÂêïÂÄ©ÔºåÂ≠ôÂÆ™Âù§*Ôºå<strong>ÁÜäÁéâÊ¥Å</strong>,
                „ÄäÂØºËà™ÂÆö‰ΩçÂ≠¶Êä•„ÄãÔºå2020Ôºå8 (5): 42-48</p>
            </li>
            <li>
                <a href="https://www.worldscientific.com/doi/abs/10.1142/S021800141953001X"><p>Improving
                    Text-Independent Chinese Writer Identification with the Aid of Character Pairs</a>,
                <strong>Y.-J. Xiong</strong>, L. Liu, S.-J. Lyu, Patrick S. P. Wang and Y. Lu*,
                International Journal of Pattern Recognition and Artificial Intelligence, 2019, 33 (2): 1953001</p>
            </li>
            <li>
                <a href="https://www.worldscientific.com/doi/abs/10.1142/9789811203527_0006"><p>Chapter 6:Improving
                    Chinese Writer Identification by Fusion of Text-dependent and Text-independent Methods</a>,
                <strong>Y.-J. Xiong</strong>, L. Liu, Patrick S. P. Wang and Y. Lu*,
                Frontiers in Patten Recognition and Artificial Intelligence, Series on Language Processing, Pattern
                Recognition, and Intelligent Systems, 2019, 5 (6): 97-112</p>
            </li>
            <li>
                <a href="https://www.worldscientific.com/doi/abs/10.1142/S0218001417560080"><p>Off-line Text-independent
                    Writer Recognition: A Survey</a>,
                <strong>Y.-J. Xiong</strong>, Y. Lu* and Patrick. S. P. Wang,
                International Journal of Pattern Recognition and Artificial Intelligence, 2017, 31 (5): 1756008</p>
            </li>
            <li>
                <a href="https://ieeexplore.ieee.org/abstract/document/8269959"><p>Chinese Writer Identification Using
                    Contour-Directional Feature and Character Pair Similarity Measurement</a>,
                <strong>Y.-J. Xiong</strong> and Y. Lu*,
                in Proceedings of the International Conference on Document Analysis and Recognition, (2017) pp.
                119‚Äì124</p>
            </li>
            <li>
                <a href="https://doi.org/10.1142/9789813143685_0008"><p>Chapter 8:Off-line Text-independent Writer
                    Identification for Chinese Handwriting</a>,
                <strong>Y.-J. Xiong</strong> and Y. Lu*,
                Advances in Chinese document and text processing, Series on Language Processing, Pattern Recognition,
                and Intelligent Systems, 2017, 2 (8): 215-234</p>
            </li>
            <li>
                <a href="https://kns.cnki.net/kcms2/article/abstract?v=wLyOq5WXWhHMAxCPWsc5s2qYqC5mDQL3K_CWilaOKKERbh_3wLJlSRFPlxM9dWlqkgNSlYYWLuhFb6KF3wUxuLtex3nsznSqWFssZF6QWyEo1lgowwmwjihHo6hrf0Gd3N1L-ErkqBsoSNuw6gfPaTsvTcVKZHxuihbOxnlt2_UZZKeNrD3_mHLlTgebmv-0xCJ3i_2cK0oWf5BHV5I3UVdYoMoq_Fly4kl5Uoxdc9U-Cax8gfJ6CMfW9QPYiTHvTvw85cSDGb7F9oMMNyq5RQ==&uniplatform=NZKPT&language=CHS">
                    <p>Âü∫‰∫é‰∏§ÊñπÂêëÂä®ÊÄÅÊó∂Èó¥ËßÑÊï¥ÁöÑÊó†ÂàÜÂâ≤ÊâãÂÜôÊ±âÂ≠óÊ£ÄÊµã</a>,
                ÈªÑÂøóÊïè*ÔºåÂßöËàúÂ•ïÔºå<strong>ÁÜäÁéâÊ¥Å</strong>,
                „ÄäËÆ°ÁÆóÊú∫Â∫îÁî®Á†îÁ©∂„ÄãÔºå2016Ôºå33(11): 3499‚Äì3502</p>
            </li>
            <li>
                <a href="https://ieeexplore.ieee.org/abstract/document/7333732"><p>Text-independent writer
                    identification using SIFT descriptor and contour-directional feature</a>,
                <strong>Y.-J. Xiong</strong>, Y. Wen, Patrick. S. P. Wang and Y. Lu*,
                in Proceedings of the International Conference on Document Analysis and Recognition, (2015) pp.
                91‚Äì95</p>
            </li>
        </ol>


</details>
